{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "190513-수업시간.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlpbokproject/jh/blob/master/190513_%EC%88%98%EC%97%85%EC%8B%9C%EA%B0%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWydLEfxD31V",
        "colab_type": "code",
        "outputId": "61aa11b6-70f4-4c5d-dfee-f0b4e2540d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?ss=ai-big-data#45dd5dd61f25'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "eng_news = soup.select('p') #[class=\"speakable-paragraph\"]')\n",
        "eng_text = eng_news[3].get_text()\n",
        "\n",
        "eng_text\n",
        "\\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"And yes, she does mean everybody's job from yours to mine and onward to the role of grain farmers in Egypt, pastry chefs in Paris and dog walkers in Oregon i.e. every job. We will now be able to help direct all workers’ actions and behavior with a new degree of intelligence that comes from predictive analytics, all stemming from the AI engines we will now increasingly depend upon.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msLYI3azwxfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67z7Sp98w7gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwKLTc0TGK-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XcLJK3QEOMW",
        "colab_type": "code",
        "outputId": "fb25ef94-2c86-4b24-9ff9-0bb224ec4e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?ss=ai-big-data#45dd5dd61f25'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "eng_news = soup.select('p') #[class=\"speakable-paragraph\"]')\n",
        "eng_text = eng_news[3].get_text()\n",
        "\n",
        "eng_text\n",
        "eng_news[2].get_text()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IBM CEO Ginni Rometty has already proclaimed that AI will change 100 percent of jobs over the next decade.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c57iDEhCEc9c",
        "colab_type": "code",
        "outputId": "568f7b02-899d-404e-9b98-f7dde0158682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "#word_tokenize() : 마침표와 구두점(온점(.), 컴마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "token1 = word_tokenize(eng_text)\n",
        "print(token1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'s\", 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i.e', '.', 'every', 'job', '.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gODiAnoEfH9",
        "colab_type": "code",
        "outputId": "04ce54a0-7bba-445f-86a2-10209fa738cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "#알파벳과 알파벳이 아닌 문자를 구분하여 토큰화\n",
        "#WordPunctTokenizer() : 알파벳과 알파벳이 아닌문자를 구분하여 토큰화\n",
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "token2 = WordPunctTokenizer().tokenize(eng_text)\n",
        "print(token2)\n",
        "\n",
        "#colab.research.google.com 에서 실습하심. WordPuncTokenizer?처럼 모르는 코드 뒤에 ?를 치면 어떤건지 알려준다?\n",
        "#https://colab.research.google.com/notebooks/welcome.ipynb#scrollTo=xitplqMNk_Hc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'\", 's', 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i', '.', 'e', '.', 'every', 'job', '.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3u41zO5FBJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WordPunctTokenizer?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyaP6wtcEl89",
        "colab_type": "code",
        "outputId": "5531c8cc-fc59-4c35-fc5f-48538e335a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "#TreebankWordTkoenizer() : 정규표현식에 기반한 토큰화\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "token = TreebankWordTokenizer().tokenize(eng_text)\n",
        "print(token)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'s\", 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i.e.', 'every', 'job.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Vz5oXaEqFm",
        "colab_type": "code",
        "outputId": "879ddd31-d349-48ed-aecd-1774558c0cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKWKBX-FXV-",
        "colab_type": "code",
        "outputId": "2a79f9d3-575e-4866-f2fb-f24b36041e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "taggedToken = pos_tag(token)\n",
        "print(taggedToken)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('And', 'CC'), ('yes', 'UH'), (',', ','), ('she', 'PRP'), ('does', 'VBZ'), ('mean', 'VB'), ('everybody', 'NN'), (\"'s\", 'POS'), ('job', 'NN'), ('from', 'IN'), ('yours', 'NNS'), ('to', 'TO'), ('mine', 'VB'), ('and', 'CC'), ('onward', 'VB'), ('to', 'TO'), ('the', 'DT'), ('role', 'NN'), ('of', 'IN'), ('grain', 'NN'), ('farmers', 'NNS'), ('in', 'IN'), ('Egypt', 'NNP'), (',', ','), ('pastry', 'NN'), ('chefs', 'NNS'), ('in', 'IN'), ('Paris', 'NNP'), ('and', 'CC'), ('dog', 'NN'), ('walkers', 'NNS'), ('in', 'IN'), ('Oregon', 'NNP'), ('i.e.', 'NN'), ('every', 'DT'), ('job.', 'NN'), ('We', 'PRP'), ('will', 'MD'), ('now', 'RB'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('help', 'VB'), ('direct', 'VB'), ('all', 'DT'), ('workers', 'NNS'), ('’', 'VBP'), ('actions', 'NNS'), ('and', 'CC'), ('behavior', 'NN'), ('with', 'IN'), ('a', 'DT'), ('new', 'JJ'), ('degree', 'NN'), ('of', 'IN'), ('intelligence', 'NN'), ('that', 'WDT'), ('comes', 'VBZ'), ('from', 'IN'), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('all', 'DT'), ('stemming', 'VBG'), ('from', 'IN'), ('the', 'DT'), ('AI', 'NNP'), ('engines', 'VBZ'), ('we', 'PRP'), ('will', 'MD'), ('now', 'RB'), ('increasingly', 'RB'), ('depend', 'VBP'), ('upon', 'NN'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX1szkXmG1wF",
        "colab_type": "text"
      },
      "source": [
        "1.4 개체명 인식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJNMgJoIG3RZ",
        "colab_type": "code",
        "outputId": "148292d4-a343-4e02-e60f-86c84dd84103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "#개체가 뭔지 인식하기 위해 미리 존재하는 사전을 사용\n",
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq8K2gUUHUJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#검색 엔진의 핵심기술\n",
        "from nltk import ne_chunk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9zTnatkHU5u",
        "colab_type": "code",
        "outputId": "dabdae28-6427-48ab-9a62-15f84a2b4a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1436
        }
      },
      "source": [
        "neToken = ne_chunk(taggedToken)\n",
        "print(neToken)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  And/CC\n",
            "  yes/UH\n",
            "  ,/,\n",
            "  she/PRP\n",
            "  does/VBZ\n",
            "  mean/VB\n",
            "  everybody/NN\n",
            "  's/POS\n",
            "  job/NN\n",
            "  from/IN\n",
            "  yours/NNS\n",
            "  to/TO\n",
            "  mine/VB\n",
            "  and/CC\n",
            "  onward/VB\n",
            "  to/TO\n",
            "  the/DT\n",
            "  role/NN\n",
            "  of/IN\n",
            "  grain/NN\n",
            "  farmers/NNS\n",
            "  in/IN\n",
            "  (GPE Egypt/NNP)\n",
            "  ,/,\n",
            "  pastry/NN\n",
            "  chefs/NNS\n",
            "  in/IN\n",
            "  (GPE Paris/NNP)\n",
            "  and/CC\n",
            "  dog/NN\n",
            "  walkers/NNS\n",
            "  in/IN\n",
            "  (GPE Oregon/NNP)\n",
            "  i.e./NN\n",
            "  every/DT\n",
            "  job./NN\n",
            "  We/PRP\n",
            "  will/MD\n",
            "  now/RB\n",
            "  be/VB\n",
            "  able/JJ\n",
            "  to/TO\n",
            "  help/VB\n",
            "  direct/VB\n",
            "  all/DT\n",
            "  workers/NNS\n",
            "  ’/VBP\n",
            "  actions/NNS\n",
            "  and/CC\n",
            "  behavior/NN\n",
            "  with/IN\n",
            "  a/DT\n",
            "  new/JJ\n",
            "  degree/NN\n",
            "  of/IN\n",
            "  intelligence/NN\n",
            "  that/WDT\n",
            "  comes/VBZ\n",
            "  from/IN\n",
            "  predictive/JJ\n",
            "  analytics/NNS\n",
            "  ,/,\n",
            "  all/DT\n",
            "  stemming/VBG\n",
            "  from/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION AI/NNP)\n",
            "  engines/VBZ\n",
            "  we/PRP\n",
            "  will/MD\n",
            "  now/RB\n",
            "  increasingly/RB\n",
            "  depend/VBP\n",
            "  upon/NN\n",
            "  ./.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVasn-WmH0Tv",
        "colab_type": "text"
      },
      "source": [
        "1.5.1 어간추출(stemming)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJAmnsKXHd43",
        "colab_type": "code",
        "outputId": "616aae19-ad86-4098-e357-686b0f00d4f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "print(\"running -> \"+ps.stem(\"running\"))\n",
        "print(\"beautiful -> \"+ps.stem(\"beautiful\"))\n",
        "print(\"believes -> \"+ps.stem(\"believes\"))\n",
        "print(\"using -> \"+ps.stem(\"using\"))\n",
        "print(\"conversation -> \"+ps.stem(\"conversation\"))\n",
        "print(\"organization -> \"+ps.stem(\"organization\"))\n",
        "print(\"studies -> \"+ps.stem(\"studies\"))\n",
        "#stemming은 그닥 많이 쓰진 않음. 변경된 어휘 자체가 의미 있는 게 아니라 짤린거다보니까 많이 쓰진 않는듯"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running -> run\n",
            "beautiful -> beauti\n",
            "believes -> believ\n",
            "using -> use\n",
            "conversation -> convers\n",
            "organization -> organ\n",
            "studies -> studi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbaTgLS1IZK8",
        "colab_type": "code",
        "outputId": "b3a44230-ba05-43d3-8969-2effcd57af42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQeQcCrfI6hL",
        "colab_type": "text"
      },
      "source": [
        "1.5.2 표제어 추출(Lemmatization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCbNqO1lInIS",
        "colab_type": "code",
        "outputId": "09537978-6858-4e52-b1b6-888b33b35d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wl = WordNetLemmatizer()\n",
        "\n",
        "print(\"running -> \"+wl.lemmatize(\"running\"))\n",
        "print(\"beautiful -> \"+wl.lemmatize(\"beautiful\"))\n",
        "print(\"believes -> \"+wl.lemmatize(\"believes\"))\n",
        "print(\"using -> \"+wl.lemmatize(\"using\"))\n",
        "print(\"conversation -> \"+wl.lemmatize(\"conversation\"))\n",
        "print(\"organization -> \"+wl.lemmatize(\"organization\"))\n",
        "print(\"studies -> \"+wl.lemmatize(\"studies\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running -> running\n",
            "beautiful -> beautiful\n",
            "believes -> belief\n",
            "using -> using\n",
            "conversation -> conversation\n",
            "organization -> organization\n",
            "studies -> study\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_ku5pBfKGQc",
        "colab_type": "text"
      },
      "source": [
        "1.6 불용어 처리(Stopword)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmYZX1fYJQ4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#불필요한 걸 다 없애게 되면, 최종적으로 분석하 때 필요한 것만 남음?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9_EFH5ZKOa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopPos = ['IN', 'CC', 'UH', 'TO', 'MD', 'DT', 'VBZ', 'VBP']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVtiHxmhKqY4",
        "colab_type": "code",
        "outputId": "f5f94381-da07-4d99-f537-93450c7575dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1137
        }
      },
      "source": [
        "#최빈어 조회. 최빈어를 조회하여 불용어 제거 대상을 선정\n",
        "from collections import Counter\n",
        "Counter(taggedToken).most_common()\n",
        "#점 찍고 컨트롤+스페이스 누르면 자동완성 끝남."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((',', ','), 3),\n",
              " (('from', 'IN'), 3),\n",
              " (('to', 'TO'), 3),\n",
              " (('and', 'CC'), 3),\n",
              " (('in', 'IN'), 3),\n",
              " (('the', 'DT'), 2),\n",
              " (('of', 'IN'), 2),\n",
              " (('will', 'MD'), 2),\n",
              " (('now', 'RB'), 2),\n",
              " (('all', 'DT'), 2),\n",
              " (('And', 'CC'), 1),\n",
              " (('yes', 'UH'), 1),\n",
              " (('she', 'PRP'), 1),\n",
              " (('does', 'VBZ'), 1),\n",
              " (('mean', 'VB'), 1),\n",
              " (('everybody', 'NN'), 1),\n",
              " ((\"'s\", 'POS'), 1),\n",
              " (('job', 'NN'), 1),\n",
              " (('yours', 'NNS'), 1),\n",
              " (('mine', 'VB'), 1),\n",
              " (('onward', 'VB'), 1),\n",
              " (('role', 'NN'), 1),\n",
              " (('grain', 'NN'), 1),\n",
              " (('farmers', 'NNS'), 1),\n",
              " (('Egypt', 'NNP'), 1),\n",
              " (('pastry', 'NN'), 1),\n",
              " (('chefs', 'NNS'), 1),\n",
              " (('Paris', 'NNP'), 1),\n",
              " (('dog', 'NN'), 1),\n",
              " (('walkers', 'NNS'), 1),\n",
              " (('Oregon', 'NNP'), 1),\n",
              " (('i.e.', 'NN'), 1),\n",
              " (('every', 'DT'), 1),\n",
              " (('job.', 'NN'), 1),\n",
              " (('We', 'PRP'), 1),\n",
              " (('be', 'VB'), 1),\n",
              " (('able', 'JJ'), 1),\n",
              " (('help', 'VB'), 1),\n",
              " (('direct', 'VB'), 1),\n",
              " (('workers', 'NNS'), 1),\n",
              " (('’', 'VBP'), 1),\n",
              " (('actions', 'NNS'), 1),\n",
              " (('behavior', 'NN'), 1),\n",
              " (('with', 'IN'), 1),\n",
              " (('a', 'DT'), 1),\n",
              " (('new', 'JJ'), 1),\n",
              " (('degree', 'NN'), 1),\n",
              " (('intelligence', 'NN'), 1),\n",
              " (('that', 'WDT'), 1),\n",
              " (('comes', 'VBZ'), 1),\n",
              " (('predictive', 'JJ'), 1),\n",
              " (('analytics', 'NNS'), 1),\n",
              " (('stemming', 'VBG'), 1),\n",
              " (('AI', 'NNP'), 1),\n",
              " (('engines', 'VBZ'), 1),\n",
              " (('we', 'PRP'), 1),\n",
              " (('increasingly', 'RB'), 1),\n",
              " (('depend', 'VBP'), 1),\n",
              " (('upon', 'NN'), 1),\n",
              " (('.', '.'), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS2gYtqBK0AY",
        "colab_type": "code",
        "outputId": "94429df9-1e89-46ce-bcb4-b47444a3d917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "stopWord = [',', 'be', 'able']\n",
        "\n",
        "word = []\n",
        "for tag in taggedToken:\n",
        "  if tag[1] not in stopPos:\n",
        "    if tag[0] not in stopWord:\n",
        "      word.append(tag[0])\n",
        "      \n",
        "print(word)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['she', 'mean', 'everybody', \"'s\", 'job', 'yours', 'mine', 'onward', 'role', 'grain', 'farmers', 'Egypt', 'pastry', 'chefs', 'Paris', 'dog', 'walkers', 'Oregon', 'i.e.', 'job.', 'We', 'now', 'help', 'direct', 'workers', 'actions', 'behavior', 'new', 'degree', 'intelligence', 'that', 'predictive', 'analytics', 'stemming', 'AI', 'we', 'now', 'increasingly', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9vnyVReLuoo",
        "colab_type": "code",
        "outputId": "e454c1c3-6e98-4180-ee6e-722febb540b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1792
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "sumtoken = TreebankWordTokenizer().tokenize(\"Obama loves fried chicken of KFC\")\n",
        "print(sumtoken)\n",
        "\n",
        "from nltk import pos_tag\n",
        "sumTaggedToken = pos_tag(sumtoken)\n",
        "print(taggedToken)\n",
        "\n",
        "from nltk import ne_chunk\n",
        "sumNeToken = ne_chunk(sumTaggedToken)\n",
        "print(neToken)\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "print(\"loves -> \" + ps.stem(\"loves\"))\n",
        "print(\"fried -> \" + ps.stem(\"fried\"))\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl = WordNetLemmatizer()\n",
        "print(\"loves -> \" + wl.lemmatize(\"loves\"))\n",
        "print(\"fried -> \" + wl.lemmatize(\"fried\"))\n",
        "\n",
        "#불용어 처리\n",
        "sumStopPos = ['IN']\n",
        "sumStopWord = ['fried']\n",
        "\n",
        "word = []\n",
        "for tag in sumTaggedToken:\n",
        "    if tag[1] not in sumStopPos:\n",
        "        if tag[0] not in sumStopWord:\n",
        "            word.append(tag[0])\n",
        "            \n",
        "print(word)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "['Obama', 'loves', 'fried', 'chicken', 'of', 'KFC']\n",
            "[('And', 'CC'), ('yes', 'UH'), (',', ','), ('she', 'PRP'), ('does', 'VBZ'), ('mean', 'VB'), ('everybody', 'NN'), (\"'s\", 'POS'), ('job', 'NN'), ('from', 'IN'), ('yours', 'NNS'), ('to', 'TO'), ('mine', 'VB'), ('and', 'CC'), ('onward', 'VB'), ('to', 'TO'), ('the', 'DT'), ('role', 'NN'), ('of', 'IN'), ('grain', 'NN'), ('farmers', 'NNS'), ('in', 'IN'), ('Egypt', 'NNP'), (',', ','), ('pastry', 'NN'), ('chefs', 'NNS'), ('in', 'IN'), ('Paris', 'NNP'), ('and', 'CC'), ('dog', 'NN'), ('walkers', 'NNS'), ('in', 'IN'), ('Oregon', 'NNP'), ('i.e.', 'NN'), ('every', 'DT'), ('job.', 'NN'), ('We', 'PRP'), ('will', 'MD'), ('now', 'RB'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('help', 'VB'), ('direct', 'VB'), ('all', 'DT'), ('workers', 'NNS'), ('’', 'VBP'), ('actions', 'NNS'), ('and', 'CC'), ('behavior', 'NN'), ('with', 'IN'), ('a', 'DT'), ('new', 'JJ'), ('degree', 'NN'), ('of', 'IN'), ('intelligence', 'NN'), ('that', 'WDT'), ('comes', 'VBZ'), ('from', 'IN'), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('all', 'DT'), ('stemming', 'VBG'), ('from', 'IN'), ('the', 'DT'), ('AI', 'NNP'), ('engines', 'VBZ'), ('we', 'PRP'), ('will', 'MD'), ('now', 'RB'), ('increasingly', 'RB'), ('depend', 'VBP'), ('upon', 'NN'), ('.', '.')]\n",
            "(S\n",
            "  And/CC\n",
            "  yes/UH\n",
            "  ,/,\n",
            "  she/PRP\n",
            "  does/VBZ\n",
            "  mean/VB\n",
            "  everybody/NN\n",
            "  's/POS\n",
            "  job/NN\n",
            "  from/IN\n",
            "  yours/NNS\n",
            "  to/TO\n",
            "  mine/VB\n",
            "  and/CC\n",
            "  onward/VB\n",
            "  to/TO\n",
            "  the/DT\n",
            "  role/NN\n",
            "  of/IN\n",
            "  grain/NN\n",
            "  farmers/NNS\n",
            "  in/IN\n",
            "  (GPE Egypt/NNP)\n",
            "  ,/,\n",
            "  pastry/NN\n",
            "  chefs/NNS\n",
            "  in/IN\n",
            "  (GPE Paris/NNP)\n",
            "  and/CC\n",
            "  dog/NN\n",
            "  walkers/NNS\n",
            "  in/IN\n",
            "  (GPE Oregon/NNP)\n",
            "  i.e./NN\n",
            "  every/DT\n",
            "  job./NN\n",
            "  We/PRP\n",
            "  will/MD\n",
            "  now/RB\n",
            "  be/VB\n",
            "  able/JJ\n",
            "  to/TO\n",
            "  help/VB\n",
            "  direct/VB\n",
            "  all/DT\n",
            "  workers/NNS\n",
            "  ’/VBP\n",
            "  actions/NNS\n",
            "  and/CC\n",
            "  behavior/NN\n",
            "  with/IN\n",
            "  a/DT\n",
            "  new/JJ\n",
            "  degree/NN\n",
            "  of/IN\n",
            "  intelligence/NN\n",
            "  that/WDT\n",
            "  comes/VBZ\n",
            "  from/IN\n",
            "  predictive/JJ\n",
            "  analytics/NNS\n",
            "  ,/,\n",
            "  all/DT\n",
            "  stemming/VBG\n",
            "  from/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION AI/NNP)\n",
            "  engines/VBZ\n",
            "  we/PRP\n",
            "  will/MD\n",
            "  now/RB\n",
            "  increasingly/RB\n",
            "  depend/VBP\n",
            "  upon/NN\n",
            "  ./.)\n",
            "loves -> love\n",
            "fried -> fri\n",
            "loves -> love\n",
            "fried -> fried\n",
            "['Obama', 'loves', 'chicken', 'KFC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YrNOhHRQ197",
        "colab_type": "code",
        "outputId": "a2527d0c-de92-484d-c58a-134719dd4fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'http://news.chosun.com/site/data/html_dir/2018/07/10/2018071004121.html'\n",
        "response = requests.get(url)\n",
        "response.encoding = 'utf-8'    # 한글이므로 encoding을 utf-8로 지정\n",
        "soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "kor_news = soup.select('div[class=\"par\"]')\n",
        "kor_text = kor_news[0].get_text()\n",
        "\n",
        "kor_text\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'교육을 삶의 최우선 순위로 두고 있는 한국의 부모들은 대학 전공 가운데 의학과 공학·과학을 중시한다. 자녀의 직업적 성공을 위해 대학 전공으로 의학과 이공계를 우선적으로 고려하는 일은 한국이 산업화 중이던 상황에선 올바른 선택이었다. 하지만 지금은 모든 것이 달라졌다. 요즘 실리콘밸리에서 확인되는 것은 4차 산업혁명 시대에는 예술과 인문학이 의학·공학만큼 중요하다는 사실이다.스티브 잡스는 자신이 대학 시절 수강했던 서체(書體) 수업이 매킨토시(애플이 1984년 발표한 개인용 컴퓨터) 개발 성공에 큰 영향을 미쳤다고 말했다. 그는 2011년 아이패드 2를 공개하면서 \"애플의 DNA는 기술만으로는 충분하지 않다. 교양과 인문학이 결합한 기술이야말로 가슴 벅찬 결과를 낳을 것\"이라며 예술과 디자인의 중요성을 강조했다. 이런 관점을 바탕으로 잡스는 세계 최고 가치를 인정받는 기업을 만들었고, 기술 산업의 새로운 표준까지 정했다.실리콘밸리에서 최근 뜨고 있는 스타 기업인 중에는 인문학 전공자들이 제법 많다. 구인·구직 소셜 네트워킹 서비스 기업인 링크드인(LinkedIn) 창업자 리드 호프만은 철학 석사 학위 소지자이며, 수잔 보이치키 유튜브 CEO는 역사와 문학을 전공했다. 메신저 개발 업체 슬랙(Slack)의 창업자 스튜어트 버터필드는 철학, 세계 최대 숙박 공유 기업인 에어비앤비의 설립자 브라이언 체스키는 미술을 전공했다. 중국 알리바바그룹의 마윈 회장의 학부 전공은 영어였다.내가 속해 있는 하버드대·듀크대 연구팀은 미국 IT 기업 창업자들의 92%가 학사 학위를, 47%는 석사 학위 이상을 갖고 있음을 밝혀냈다. 창업자들의 세부 전공을 보면 37%만 공학·컴퓨터 기술이며, 수학 전공자는 2%뿐이었다. 이들의 전공은 경영·회계·보건·예술·인문학 등 매우 다양했다.컴퓨터 주변기기 제조 업체 로지텍의 브랙큰 대럴 CEO도 영문학을 전공했다. 최근 내가 그에게 \"어떻게 5년여 만에 회사 주가를 450% 올릴 수 있었느냐\"고 물었더니 그는 \"우리 회사가 만드는 모든 제품의 디자인을 쉼 없이 고민했기 때문에 가능했다. 기술 관련 제품의 성공에 가장 중요한 것은 디자인\"이라고 답했다.4차 산업혁명은 \\'혁신의 규칙\\'을 바꾸는 일이다. 여기에는 컴퓨터와 인공지능, 디지털 의술, 로봇공학, 합성생물학 등 광범위한 기술이 활용된다. 의학·인공지능과 센서를 융합하면 인간의 건강을 진단하고 질병을 예방하는 \\'디지털 의사\\'를 만들 수 있다. 유전체학과 유전자 편집을 이용해 가뭄에 강하고 인류 전체를 먹여 살릴 새 식물을 개발할 수 있다. 인공지능 로봇을 사용해 노인들을 위한 \\'디지털 친구\\'도 가능하다. 초소형 물질의 발전은 모든 사람이 충분히 이용할 수 있는 \\'태양열 저장 기술\\'의 새 시대를 열 것이다.이런 해결책을 이끌어내는 데는 생물학·교육·의료·인간행동 등 여러 분야에 대한 지식이 필요하다. 우리가 처한 거대한 사회·기술적 도전에 대처하려면 인류를 둘러싼 다양한 배경과 맥락에 대해 비판적 사고 능력이 필수적이다. 이는 인문학 전공자들이 가장 잘 훈련받은 분야이다.일례로 음악·예술·문학과 심리학에서 비롯한 공감(共感) 능력은 디자인에 큰 장점이 된다. 로마제국의 흥망성쇠와 계몽주의를 공부한 역사학도는 기술의 인간적 요소와 유용성에 대한 통찰력을 가질 수 있다. 심리학 전공자는 사람에게 동기(動機)부여가 무엇이며, 사용자들이 원하는 게 무엇인지를 공학 한 분야에서만 일해온 엔지니어들보다 잘 이해할 수 있다. 우리가 상상하는 물건을 3D로 만들 수 있게 되면 음악가나 화가들의 세상이 될지도 모른다.\"자녀가 미래에 어떤 직업을 택하면 좋겠는가\"라는 질문을 받을 때 나는 \"아이들이 스스로 하고 싶은 것을 선택하도록 내버려 두는 게 최선\"이라고 답한다. 과거 우리 부모들이 우리에게 공부를 강요해서 학습을 \\'억지로 해야 하는 따분한 일\\'로 여기게 했던 방식을 따라 해선 안 된다. 그 대신 자녀가 자신의 열정을 추구하고 배우는 걸 즐길 수 있도록 북돋아야 한다.기술을 통해 놀라운 미래를 창조하고 새로운 산업혁명 시대에 리더가 되기 위해 한국에서는 공학자들과 손잡고 일할 음악가와 화가가 더 많이 필요하다. 이제는 과학·공학·의학뿐 아니라 창의성과 디자인에도 진정한 관심을 쏟아야 한다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUsLAU85NWuH",
        "colab_type": "text"
      },
      "source": [
        "2.1 실습용 한글기사 수집"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49IEgDymNVxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wny-y0ESGiz",
        "colab_type": "text"
      },
      "source": [
        "2.2 한글 토큰화 및 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLQk8dXDSIML",
        "colab_type": "code",
        "outputId": "94881b45-9360-45f6-d236-a0be78276335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "#konlpy 설치\n",
        "!pip install konlpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/3d/4e983cd98d87b50b2ab0387d73fa946f745aa8164e8888a714d5129f9765/konlpy-0.5.1-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 2.8MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.5.7 (from konlpy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/4b/60a3e63d51714d4d7ef1b1efdf84315d118a0a80a5b085bb52a7e2428cdc/JPype1-0.6.3.tar.gz (168kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 41.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: JPype1\n",
            "  Building wheel for JPype1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/2b/e8/c0b818ac4b3d35104d35e48cdc7afe27fc06ea277feed2831a\n",
            "Successfully built JPype1\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-0.6.3 konlpy-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKt01EqBSoUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#출력을 위해서 임시 class \n",
        "class List(list): \n",
        "    def __str__(self): \n",
        "        return \"[\" + \", \".join([\"%s\" % x for x in self]) + \"]\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iii2qhMoSMO7",
        "colab_type": "code",
        "outputId": "44b8c1ea-27a2-4eb3-9bd0-e35072be29e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "#코모란(Komoran) 토큰화\n",
        "from konlpy.tag import Komoran\n",
        "komoran = Komoran()\n",
        "komoran_tokens = komoran.morphs(kor_text)\n",
        "print(List(komoran_tokens))\n",
        "\n",
        "#한나눔(Hannanum) 토큰화\n",
        "from konlpy.tag import Hannanum\n",
        "hannanum = Hannanum()\n",
        "hannanum_tokens = hannanum.morphs(kor_text)\n",
        "print(List(hannanum_tokens))\n",
        "\n",
        "#Okt 토큰화\n",
        "from konlpy.tag import Okt\n",
        "okt =Okt()\n",
        "okt_tokens = okt.morphs(kor_text)\n",
        "print(List(okt_tokens))\n",
        "\n",
        "#Kkma 토근화\n",
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()\n",
        "kkma_tokens = kkma.morphs(kor_text)\n",
        "print(List(kkma_tokens))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[교육, 을, 삶, 의, 최, 우선, 순위, 로, 두, 고, 있, 는, 한국, 의, 부모, 들, 은, 대학, 전공, 가운데, 의학, 과, 공학, ·, 과학, 을, 중시, 하, ㄴ다, ., 자녀, 의, 직업, 적, 성공, 을, 위하, 아, 대학, 전공, 으로, 의학, 과, 이공, 계, 를, 우선, 적, 으로, 고려, 하, 는, 일, 은, 한국, 이, 산업화, 중, 이, 던, 상황, 에서, ㄴ, 올바르, ㄴ, 선택, 이, 었, 다, ., 하지만, 지금, 은, 모든, 것, 이, 달라지, 었, 다, ., 요즘, 실리콘밸리, 에서, 확인, 되, 는, 것, 은, 4, 차, 산업, 혁명, 시대, 에, 는, 예술, 과, 인문학, 이, 의학, ·, 공학, 만큼, 중요, 하, 다는, 사실, 이, 다, ., 스티브 잡스, 는, 자신, 이, 대학, 시절, 수강, 하, 았, 던, 서, 체, (, 書體, ), 수업, 이, 매킨토시, (, 애플, 이, 1984, 년, 발표, 하, ㄴ, 개인용 컴퓨터, ), 개발, 성공, 에, 크, ㄴ, 영향, 을, 미치, 었, 다고, 말, 하, 았, 다, ., 그, 는, 2011, 년, 아이패드 2, 를, 공개, 하, 면서, \", 애플, 의, DNA, 는, 기술, 만, 으로, 는, 충분, 하, 지, 않, 다, ., 교양, 과, 인문학, 이, 결합, 하, ㄴ, 기술, 이야말로, 가슴, 벅차, ㄴ, 결과, 를, 낳, 을, 것, \", 이, 라며, 예술, 과, 디자인, 의, 중요, 성, 을, 강조, 하, 았, 다, ., 이런, 관점, 을, 바탕, 으로, 잡스, 는, 세계, 최고, 가치, 를, 인정받, 는, 기업, 을, 만들, 었, 고, ,, 기술, 산업, 의, 새롭, ㄴ, 표준, 까지, 정하, 았, 다, ., 실리콘밸리, 에서, 최근, 뜨, 고, 있, 는, 스타, 기업인, 중, 에, 는, 인문학, 전공자, 들, 이, 제법, 많, 다, ., 구인, ·, 구직, 소, 시, 어, ㄹ, 네트, 워킹, 서비스, 기업인, 링크, 드, 인, (, LinkedIn, ), 창업자, 리드, 호프만, 은, 철학, 석사, 학위, 소지자, 이, 며, ,, 수잔, 보이, 치, 하, 기, 유튜브, CEO, 는, 역사, 와, 문학, 을, 전공, 하, 았, 다, ., 메신저, 개발, 업체, 슬랙(Slack)의, 창업자, 스튜어트, 버터필드, 는, 철학, ,, 세계, 최대, 숙박, 공유, 기업인, 에어비앤비, 의, 설립자, 브라이언, 체, 스키, 는, 미술, 을, 전공, 하, 았, 다, ., 중국, 알리바바, 그룹, 의, 마윈, 회장, 의, 학부, 전공, 은, 영어, 이, 었, 다, ., 내, 가, 속하, 아, 있, 는, 하버드대, ·, 듀크, 대, 연구, 팀, 은, 미국, IT, 기업, 창업자, 들, 의, 92, %, 가, 학사, 학위, 를, ,, 47, %, 는, 석사, 학위, 이상, 을, 갖, 고, 있, 음, 을, 밝혀내, 었, 다, ., 창업자, 들, 의, 세부, 전공, 을, 보, 면, 37, %, 만, 공학, ·, 컴퓨터, 기술, 이, 며, ,, 수학, 전공자, 는, 2, %, 뿐, 이, 었, 다, ., 이, 들, 의, 전공, 은, 경영, ·, 회계, ·, 보건, ·, 예술, ·, 인문학, 등, 매우, 다양, 하, 었, 다, ., 컴퓨터, 주변기기, 제조, 업체, 로지텍, 의, 브랙큰, 대, 러, ㄹ, CEO, 도, 영문학, 을, 전공, 하, 았, 다, ., 최근, 내, 가, 그, 에게, \", 어떻, 게, 5, 년, 이, 어, 만, 에, 회사, 주가, 를, 450, %, 올리, ㄹ, 수, 있, 었, 느냐, \", 고, 묻, 었, 더니, 그, 는, \", 우리, 회사, 가, 만들, 는, 모든, 제품, 의, 디자인, 을, 쉬, ㅁ, 없이, 고민, 하, 았, 기, 때문, 에, 가능, 하, 었, 다, ., 기술, 관련, 제품, 의, 성공, 에, 가장, 중요, 하, ㄴ, 것, 은, 디자인, \", 이라고, 답, 하, 았, 다, ., 4, 차, 산업, 혁명, 은, ', 혁신, 의, 규칙, ', 을, 바꾸, 는, 일, 이, 다, ., 여기, 에, 는, 컴퓨터, 와, 인공지능, ,, 디지털, 의술, ,, 로봇공학, ,, 합성생물학, 등, 광범위, 하, ㄴ, 기술, 이, 활용, 되, ㄴ다, ., 의학, ·, 인공지능, 과, 센서, 를, 융합, 하, 면, 인간, 의, 건강, 을, 진단, 하, 고, 질병, 을, 예방, 하, 는, ', 디지털, 의사, ', 를, 만들, ㄹ, 수, 있, 다, ., 유전체학, 과, 유전자, 편집, 을, 이용, 하, 아, 가뭄, 에, 강하, 고, 인류, 전체, 를, 먹이, 어, 살리, ㄹ, 새, 식물, 을, 개발, 하, ㄹ, 수, 있, 다, ., 인공지능, 로봇, 을, 사용, 하, 아, 노인, 들, 을, 위하, ㄴ, ', 디지털, 친구, ', 도, 가능, 하, 다, ., 초소, 형, 물질, 의, 발전, 은, 모든, 사람, 이, 충분히, 이용, 하, ㄹ, 수, 있, 는, ', 태양열, 저장, 기술, ', 의, 새 시대, 를, 열, 것, 이, 다, ., 이런, 해결책, 을, 이끌, 어, 내, 는, 데, 는, 생물학, ·, 교육, ·, 의료, ·, 인간, 행동, 등, 여러, 분야, 에, 대하, ㄴ, 지식, 이, 필요, 하, 다, ., 우리, 가, 처하, ㄴ, 거대, 하, ㄴ, 사회, ·, 기술, 적, 도전, 에, 대처, 하, 려면, 인류, 를, 둘러싸, ㄴ, 다양, 하, ㄴ, 배경, 과, 맥락, 에, 대하, 아, 비판적 사고, 능력, 이, 필수, 적, 이, 다, ., 이, 는, 인문학, 전공자, 들, 이, 가장, 잘, 훈련, 받, 은, 분야, 이, 다, ., 일례, 로, 음악, ·, 예술, ·, 문학, 과, 심리학, 에서, 비롯, 하, ㄴ, 공감, (, 共感, ), 능력, 은, 디자인, 에, 크, ㄴ, 장점, 이, 되, ㄴ다, ., 로마제국, 의, 흥망성쇠, 와, 계몽주의, 를, 공부, 하, ㄴ, 역사학도, 는, 기술, 의, 인간, 적, 요소, 와, 유용성, 에, 대하, ㄴ, 통찰력, 을, 가지, ㄹ, 수, 있, 다, ., 심리학, 전공자, 는, 사람, 에게, 동기, (, 動機, ), 부여, 가, 무엇, 이, 며, ,, 사용자, 들, 이, 원하, 는, 게, 무엇, 인지, 를, 공학, 한, 분야, 에서, 만, 일, 하, 아, 오, ㄴ, 엔지니어, 들, 보다, 잘, 이해, 하, ㄹ, 수, 있, 다, ., 우리, 가, 상상, 하, 는, 물건, 을, 3D, 로, 만들, ㄹ, 수, 있, 게, 되, 면, 음악가, 나, 화가, 들, 의, 세상, 이, 되, ㄹ지, 도, 모르, ㄴ다, ., \", 자녀, 가, 미래, 에, 어떤, 직업, 을, 택하, 면, 좋, 겠, 는가, \", 이, 라는, 질문, 을, 받, 을, 때, 나, 는, \", 아이들, 이, 스스로, 하, 고, 싶, 은, 것, 을, 선택, 하, 도록, 내버리, 어, 두, 는, 게, 최선, \", 이라고, 답하, ㄴ다, ., 과거, 우리, 부모, 들, 이, 우리, 에게, 공부, 를, 강요, 하, 아서, 학습, 을, ', 억지로, 하, 아야, 하, 는, 따분, 하, ㄴ, 일, ', 로, 여기, 게, 하, 았, 던, 방식, 을, 따르, 아, 하, 아서, ㄴ, 안, 되, ㄴ다, ., 그, 대신, 자녀, 가, 자신, 의, 열정, 을, 추구, 하, 고, 배우, 는, 걸, ㄹ, 즐기, ㄹ, 수, 있, 도록, 북돋, 아야, 하, ㄴ다, ., 기술, 을, 통하, 아, 놀랍, ㄴ, 미래, 를, 창조, 하, 고, 새롭, ㄴ, 산업, 혁명, 시대, 에, 리더, 가, 되, 기, 위하, 아, 한국, 에서, 는, 공학자, 들, 과, 손잡, 고, 일, 하, ㄹ, 음악가, 와, 화가, 가, 더, 많이, 필요, 하, 다, ., 이제, 는, 과학, ·, 공학, ·, 의학, 뿐, 아니, 라, 창의성, 과, 디자인, 에, 도, 진정, 하, ㄴ, 관심, 을, 쏟, 아야, 하, ㄴ다, .]\n",
            "[교육, 을, 삶, 의, 최우선, 순위, 로, 두, 고, 있, 는, 한국의, 부모들, 은, 대학, 전공, 가운데, 의학, 과, 공학·과학, 을, 중시, 하, ㄴ다, ., 자녀, 의, 직업적, 성공, 을, 위하, 어, 대학, 전공, 으로, 의학, 과, 이공계, 를, 우선적, 으로, 고, 려, 하, 는, 일, 은, 한국, 이, 산업화, 중, 이, 던, 상황, 에선, 올바르, ㄴ, 선택, 이, 었다, ., 하, 지만, 지금, 은, 모든, 것, 이, 다르, 아, 지, 었다, ., 요즘, 실리콘밸리, 에서, 확인, 되, 는, 것, 은, 4차, 산업혁명, 시대, 에는, 예술, 과, 인문학, 이, 의학·공학만큼, 중요, 하, 다는, 사실, 이, 다, ., 스티브, 잡스, 는, 자신, 이, 대학, 시절, 수강, 하, 었던, 서체(書體), 수업, 이, 매킨토시(애플, 이, 1984년, 발표, 하, ㄴ, 개인용, 컴퓨터, ), 개발, 성공, 에, 크, ㄴ, 영향, 을, 미치, 었다, 고, 말, 하, 었다, ., 그, 는, 2011년, 아이패드, 2, 를, 공개, 하, 면서, \", 애플, 의, DNA, 는, 기술만, 으로는, 충분, 하, 지, 않, 다, ., 교양, 과, 인문학, 이, 결합, 하, ㄴ, 기술, 이야말로, 가슴, 벅차, ㄴ, 결과, 를, 낳, 을, 것, \", 이, 라며, 예술, 과, 디자인, 의, 중요성, 을, 강조, 하, 었다, ., 이런, 관점, 을, 바탕, 으로, 잡스, 는, 세계, 최고, 가치, 를, 인정, 받, 는, 기업, 을, 만들, 었고, ,, 기술, 산업, 의, 새롭, 은, 표준, 까지, 정하, 었다, ., 실리콘밸리, 에서, 최근, 뜨, 고, 있, 는, 스타, 기업, 이, ㄴ, 중, 에는, 인문학, 전공자들, 이, 제법, 많, 다, ., 구인·구직, 소셜, 네트워킹, 서비스, 기업, 이, ㄴ, 링크드인(LinkedIn), 창업자, 리드, 호프, 만은, 철학, 석사, 학위, 소지자, 이, 며, ,, 수잔, 보이치키, 유튜브, CEO, 는, 역사, 와, 문학, 을, 전공, 하, 었다, ., 메신저, 개발, 업체, 슬랙(Slack), 의, 창업자, 스튜어트, 버터필드, 는, 철학, ,, 세계, 최대, 숙박, 공유, 기업, 이, ㄴ, 에어비앤비, 의, 설립자, 브라이언, 체스키, 는, 미술, 을, 전공, 하, 었다, ., 중국, 알리바바그룹, 의, 마윈, 회장, 의, 학부, 전공, 은, 영어, 이, 었다, ., 나, 가, 속하, 어, 있, 는, 하버드대·듀크대, 연구팀, 은, 미국, IT, 기업, 창업자들, 의, 92, %, 가, 학사, 학위, 를, ,, 47, %, 는, 석사, 학위, 이상, 을, 갖, 고, 있, 음, 을, 밝히, 어, 내, 었다, ., 창업자들, 의, 세부, 전공, 을, 보, 면, 37, %, 만, 공학·컴퓨터, 기술, 이, 며, ,, 수학, 전공자, 는, 2, %, 뿐, 이, 었다, ., 이, 들, 의, 전공, 은, 경영·회계·보건·예술·인문학, 등, 매우, 다양, 하, 었다, ., 컴퓨터, 주변기, 이, 기, 제조, 업체, 로지텍, 의, 브랙큰, 대럴, CEO, 도, 영문학, 을, 전공, 하, 었다, ., 최근, 나, 가, 그, 에게, \", 어떻, 게, 5년여, 만, 에, 회사, 주가, 를, 450, %, 올리, ㄹ, 수, 있, 었느냐, \", 고, 묻, 었더니, 그, 는, \", 우리, 회사, 가, 만들, 는, 모든, 제품, 의, 디자인, 을, 쉬, ㅁ, 없이, 고민, 하, 었기, 때문, 에, 가능, 하, 었다, ., 기술, 관련, 제품, 의, 성공, 에, 가장, 중요, 하, ㄴ, 것, 은, 디자인, \", 이, 라, 고, 답, 하, 었다, ., 4차, 산업혁명, 은, ', 혁신, 의, 규칙, ', 을, 바꾸, 는, 일, 이, 다, ., 여기, 에는, 컴퓨터, 와, 인공지능, ,, 디지털, 의술, ,, 로봇공학, ,, 합성생물학, 등, 광범위, 하, ㄴ, 기술, 이, 활용, 되, ㄴ다, ., 의학·인공지능, 과, 센서, 를, 융합, 하, 면, 인간, 의, 건강, 을, 진단, 하고, 질병, 을, 예방, 하, 는, ', 디지털, 의사, ', 를, 만들, ㄹ, 수, 있, 다, ., 유전체학, 과, 유전자, 편집, 을, 이용, 하, 어, 가뭄, 에, 강하, 고, 인류, 전체, 를, 먹이, 어, 살리, ㄹ, 새, 식물, 을, 개발, 하, ㄹ, 수, 있, 다, ., 인공지능, 로봇, 을, 사용, 하, 어, 노인들, 을, 위하, ㄴ, ', 디지털, 친구, ', 도, 가능, 하, 다, ., 초소형, 물질, 의, 발전, 은, 모든, 사람, 이, 충분히, 이용, 하, ㄹ, 수, 있, 는, ', 태양열, 저장, 기술, ', 의, 새, 시대, 를, 열, ㄹ, 것, 이, 다, ., 이런, 해결책, 을, 이끌, 어, 내, 는, 데, 는, 생물학·교육·의료·인간행동, 등, 여러, 분야, 에, 대하, ㄴ, 지식, 이, 필요, 하, 다, ., 우리, 가, 처하, ㄴ, 거대, 하, ㄴ, 사회·기술적, 도전, 에, 대처, 하, 려면, 인류, 를, 둘러싸, ㄴ, 다양한, 배경, 과, 맥락, 에, 대, 어, 하, 어, 비판적, 사, 고, 능력, 이, 필수적, 이, 다, ., 이, 는, 인문학, 전공자들, 이, 가장, 잘, 훈련, 받, 은, 분야, 이, 다, ., 일례, 로, 음악·예술·문학, 과, 심리학, 에서, 비롯, 하, ㄴ, 공감(共感), 능력, 은, 디자인, 에, 크, ㄴ, 장점, 이, 되, ㄴ다, ., 로마제국, 의, 흥망성쇠, 와, 계몽주의, 를, 공부, 하, ㄴ, 역사학도, 는, 기술, 의, 인간적, 요소, 와, 유용성, 에, 대하, ㄴ, 통찰력, 을, 가, 아, 지, ㄹ, 수, 있, 다, ., 심리학, 전공자, 는, 사람, 에게, 동기(動機)부여, 가, 무엇, 이, 며, ,, 사용자들, 이, 원하, 는, 것, 이, 무엇, 이, ㄴ, 지, 를, 공학, 하, ㄴ, 분야, 에서만, 일, 하, 어, 오, ㄴ, 엔지니어들보, 이, 다, 잘, 이해, 하, ㄹ, 수, 있, 다, ., 우리, 가, 상상, 하, 는, 물건, 을, 3D, 로, 만들, ㄹ, 수, 있, 게, 되, 면, 음악, 가나, 화가들, 의, 세상, 이, 되, ㄹ지, 도, 모르, ㄴ다, .\", 자녀, 가, 미래, 에, 어떤, 직업, 을, 택하, 면, 좋, 겠는가, \", 라는, 질문, 을, 받, 을, 때, 나, 는, \", 아이들, 이, 스스로, 하, 고, 싶, 은, 것, 을, 선택, 하, 도록, 내, 어, 버리, 어, 두, 는, 것, 이, 최선, \", 이, 라, 고, 답, 하, ㄴ다, ., 과거, 우리, 부모들, 이, 우리, 에게, 공부, 를, 강요, 하, 어서, 학습, 을, ', 억지로, 하, 어야, 하, 는, 따분한, 일, ', 로, 여기, 이, 게, 하, 었던, 방식, 을, 따르, 아, 하, 어선, 안, 되, ㄴ다, ., 그, 대, 이, 시ㄴ, 자녀, 가, 자신, 의, 열정, 을, 추구, 하고, 배우, 는, 거, ㄹ, 즐기, ㄹ, 수, 있, 도록, 북돋, 아, 하, ㄴ다, ., 기술, 을, 통하, 어, 놀랍, 은, 미래, 를, 창조, 하고, 새롭, 은, 산업혁명, 시대, 에, 리, 이, 더어, 가, 아, 되, 기, 위하, 어, 한국에서, 는, 공학자들, 과, 손잡, 고, 일할, 음악가, 와, 화가, 가, 더, 많, 이, 필요, 하, 다, ., 이제, 는, 과학·공학·의학뿐, 아니, 라, 창의성, 과, 디자인, 에도, 진정한, 관심, 을, 쏟, 아, 하, ㄴ다, .]\n",
            "[교육, 을, 삶, 의, 최, 우선, 순위, 로, 두고, 있는, 한국, 의, 부모, 들, 은, 대학, 전공, 가운데, 의학과, 공학, ·, 과학, 을, 중시, 한다, ., 자녀, 의, 직업, 적, 성공, 을, 위해, 대학, 전공, 으로, 의학과, 이공, 계, 를, 우선, 적, 으로, 고려, 하는, 일, 은, 한국, 이, 산업화, 중, 이던, 상황, 에선, 올바른, 선택, 이었다, ., 하지만, 지금, 은, 모든, 것, 이, 달라졌다, ., 요즘, 실리콘밸리, 에서, 확인, 되는, 것, 은, 4, 차, 산업혁명, 시대, 에는, 예술, 과, 인문학, 이, 의학, ·, 공학, 만큼, 중요하다는, 사실, 이다, ., 스티브, 잡스, 는, 자신, 이, 대학, 시절, 수강, 했던, 서체, (, 書體, ), 수업, 이, 매킨토시, (, 애플, 이, 1984년, 발표, 한, 개인, 용, 컴퓨터, ), 개발, 성공, 에, 큰, 영향, 을, 미쳤다고, 말, 했다, ., 그, 는, 2011년, 아이패드, 2, 를, 공개, 하면서, \", 애플, 의, DNA, 는, 기술, 만으로는, 충분하지, 않다, ., 교양, 과, 인문학, 이, 결합, 한, 기술, 이야말로, 가슴, 벅찬, 결과, 를, 낳을, 것, \", 이, 라며, 예술, 과, 디자인, 의, 중요성, 을, 강조, 했다, ., 이런, 관점, 을, 바탕, 으로, 잡스, 는, 세계, 최고, 가치, 를, 인정받는, 기업, 을, 만들었고, ,, 기술, 산업, 의, 새로운, 표준, 까지, 정, 했다, ., 실리콘밸리, 에서, 최근, 뜨고, 있는, 스타, 기업인, 중, 에는, 인문학, 전공자, 들, 이, 제법, 많다, ., 구인, ·, 구직, 소셜, 네트워킹, 서비스, 기업인, 링크드인, (, LinkedIn, ), 창업, 자, 리드, 호프, 만은, 철학, 석사, 학위, 소지, 자, 이며, ,, 수, 잔, 보이, 치키, 유튜브, CEO, 는, 역사, 와, 문학, 을, 전공, 했다, ., 메신저, 개발, 업체, 슬랙, (, Slack, ), 의, 창업, 자, 스튜어트, 버터, 필드, 는, 철학, ,, 세계, 최대, 숙박, 공유, 기업인, 에어비앤비, 의, 설립, 자, 브라이언, 체, 스키, 는, 미술, 을, 전공, 했다, ., 중국, 알리바바, 그룹, 의, 마윈, 회장, 의, 학부, 전공, 은, 영어, 였다, ., 내, 가, 속, 해, 있는, 하버드대, ·, 듀크, 대, 연, 구, 팀, 은, 미국, IT, 기업, 창업, 자, 들, 의, 92%, 가, 학사, 학위, 를, ,, 47%, 는, 석사, 학위, 이상, 을, 갖고, 있, 음, 을, 밝혀냈다, ., 창업, 자, 들, 의, 세부, 전공, 을, 보면, 37%, 만, 공학, ·, 컴퓨터, 기술, 이며, ,, 수학, 전공자, 는, 2%, 뿐이었다, ., 이, 들, 의, 전공, 은, 경영, ·, 회계, ·, 보건, ·, 예술, ·, 인문학, 등, 매우, 다양했다, ., 컴퓨터, 주변기기, 제조, 업체, 로지텍, 의, 브랙큰, 대럴, CEO, 도, 영문학, 을, 전공, 했다, ., 최근, 내, 가, 그, 에게, \", 어떻게, 5년, 여, 만에, 회사, 주가, 를, 450%, 올릴, 수, 있었느냐, \", 고, 물었더니, 그, 는, \", 우리, 회사, 가, 만드는, 모든, 제품, 의, 디자인, 을, 쉼, 없이, 고민, 했기, 때문, 에, 가능했다, ., 기술, 관련, 제품, 의, 성공, 에, 가장, 중요한, 것, 은, 디자인, \", 이라고, 답, 했다, ., 4, 차, 산업혁명, 은, ', 혁신, 의, 규칙, ', 을, 바꾸는, 일이, 다, ., 여기, 에는, 컴퓨터, 와, 인공, 지능, ,, 디지털, 의술, ,, 로봇공학, ,, 합성생물학, 등, 광범위한, 기술, 이, 활용, 된다, ., 의학, ·, 인공, 지능, 과, 센서, 를, 융합, 하면, 인간, 의, 건강, 을, 진단, 하고, 질병, 을, 예방, 하는, ', 디지털, 의사, ', 를, 만들, 수, 있다, ., 유전체학, 과, 유전자, 편집, 을, 이용, 해, 가뭄, 에, 강하고, 인류, 전체, 를, 먹여, 살릴, 새, 식물, 을, 개발, 할, 수, 있다, ., 인공, 지능, 로봇, 을, 사용, 해, 노인, 들, 을, 위, 한, ', 디지털, 친구, ', 도, 가능하다, ., 초소, 형, 물질, 의, 발전, 은, 모든, 사람, 이, 충분히, 이용, 할, 수, 있는, ', 태양열, 저장, 기술, ', 의, 새, 시대, 를, 열, 것, 이다, ., 이런, 해결, 책, 을, 이끌어내는, 데, 는, 생물학, ·, 교육, ·, 의료, ·, 인간, 행동, 등, 여러, 분야, 에, 대한, 지식, 이, 필요하다, ., 우리, 가, 처, 한, 거대한, 사회, ·, 기술, 적, 도전, 에, 대처, 하려면, 인류, 를, 둘러싼, 다양한, 배경, 과, 맥락, 에, 대해, 비판, 적, 사고, 능력, 이, 필수, 적, 이다, ., 이는, 인문학, 전공자, 들, 이, 가장, 잘, 훈련, 받은, 분야, 이다, ., 일례, 로, 음악, ·, 예술, ·, 문학, 과, 심리학, 에서, 비롯, 한, 공감, (, 共感, ), 능력, 은, 디자인, 에, 큰, 장점, 이, 된다, ., 로마제국, 의, 흥망, 성쇠, 와, 계몽, 주의, 를, 공부, 한, 역사학도, 는, 기술, 의, 인간, 적, 요소, 와, 유용성, 에, 대한, 통찰, 력, 을, 가질, 수, 있다, ., 심리학, 전공자, 는, 사람, 에게, 동기, (, 動機, ), 부여, 가, 무엇, 이며, ,, 사용자, 들, 이, 원하는, 게, 무엇, 인지, 를, 공학, 한, 분야, 에서만, 일, 해온, 엔지니어, 들, 보다, 잘, 이해, 할, 수, 있다, ., 우리, 가, 상상, 하는, 물건, 을, 3, D, 로, 만들, 수, 있게, 되면, 음악가, 나, 화가, 들, 의, 세상, 이, 될지도, 모른다, .\", 자녀, 가, 미래, 에, 어떤, 직업, 을, 택하, 면, 좋겠는가, \", 라는, 질문, 을, 받을, 때, 나, 는, \", 아이, 들, 이, 스스로, 하고, 싶은, 것, 을, 선택, 하도록, 내버려, 두는, 게, 최선, \", 이라고, 답, 한다, ., 과거, 우리, 부모, 들, 이, 우리, 에게, 공부, 를, 강요, 해서, 학습, 을, ', 억지로, 해야, 하는, 따분한, 일, ', 로, 여기, 게, 했던, 방식, 을, 따라, 해선, 안, 된다, ., 그, 대신, 자녀, 가, 자신, 의, 열정, 을, 추구, 하고, 배우는, 걸, 즐길, 수, 있도록, 북, 돋아야, 한다, ., 기술, 을, 통해, 놀라운, 미래, 를, 창조, 하고, 새로운, 산업혁명, 시대, 에, 리더, 가, 되기, 위해, 한국, 에서는, 공학자, 들, 과, 손잡고, 일, 할, 음악가, 와, 화가, 가, 더, 많이, 필요하다, ., 이제, 는, 과학, ·, 공학, ·, 의학, 뿐, 아니라, 창의성, 과, 디자인, 에도, 진정한, 관심, 을, 쏟아야, 한다, .]\n",
            "[교육, 을, 삶, 의, 최, 우선, 순위, 로, 두, 고, 있, 는, 한국, 의, 부모, 들, 은, 대학, 전공, 가운데, 의학, 과, 공학, ·, 과학, 을, 중시, 하, ㄴ다, ., 자녀, 의, 직업적, 성공, 을, 위하, 어, 대학, 전공, 으로, 의학, 과, 이공계, 를, 우선적, 으로, 고려, 하, 는, 일, 은, 한국, 이, 산업화, 중이, 덜, ㄴ, 상황, 에서, 는, 올바르, ㄴ, 선택, 이, 었, 다, ., 하지만, 지금, 은, 모든, 것, 이, 달라지, 었, 다, ., 요즘, 실리콘밸리, 에서, 확인, 되, 는, 것, 은, 4, 차, 산업, 혁명, 시대, 에, 는, 예술, 과, 인문학, 이, 의학, ·, 공학, 만큼, 중요, 하다, 는, 사실, 이, 다, ., 스티브, 잡스, 는, 자신, 이, 대학, 시절, 수강, 하, 었, 더, ㄴ, 서체, (, 書體, ), 수업, 이, 매킨토시, (, 애플, 이, 1984, 년, 발표, 하, ㄴ, 개인용, 컴퓨터, ), 개발, 성공, 에, 크, ㄴ, 영향, 을, 미치, 었, 다고, 말하, 었, 다, ., 그, 는, 2011, 년, 아이, 패드, 2, 를, 공개, 하, 면서, \", 애플, 의, DNA, 는, 기술, 만, 으로, 는, 충분, 하, 지, 않, 다, ., 교양, 과, 인문학, 이, 결합, 하, ㄴ, 기술, 이야말로, 가슴, 벅차, ㄴ, 결과, 를, 낳, 을, 것, \", 이, 라며, 예술과, 디자인, 의, 중요성, 을, 강조, 하, 었, 다, ., 이런, 관점, 을, 바탕, 으로, 잡스, 는, 세계, 최고, 가치, 를, 인정받, 는, 기업, 을, 만들, 었, 고, ,, 기술, 산업, 의, 새롭, ㄴ, 표준, 까지, 정하, 었, 다, ., 실리콘, 밸리, 에서, 최근, 뜨, 고, 있, 는, 스타, 기업인, 중, 에, 는, 인문학, 전공자, 들, 이, 제법, 많, 다, ., 구인, ·, 구직, 소, 셜, 네트, 워킹, 서비스, 기업인, 링크, 드이, ㄴ, (, LinkedIn, ), 창, 업자, 리드, 호프만, 은, 철학, 석사, 학위, 소지자, 이, 며, ,, 수, 잔, 보이, 하, 지, 키, 유, 튜브, CEO, 는, 역사, 와, 문학, 을, 전공, 하, 었, 다, ., 메신저, 개발, 업체, 슬, ㄹ, 랙, (, Slack, ), 의, 창업자, 스튜, 어트, 버터, 필드, 는, 철학, ,, 세계, 최대, 숙박, 공유, 기업인, 에어, 비, 앤, 비의, 설립자, 브라, 이언, 체, 스키, 는, 미술, 을, 전공, 하, 었, 다, ., 중국, 알, 리, 바, 바, 그룹, 의, 마, 윈, 회장, 의, 학부, 전공, 은, 영어, 이, 었, 다, ., 내, 가, 속하, 어, 있, 는, 하버드, 대, ·, 듀, 크, 대, 연구, 팀, 은, 미국, IT, 기업, 창업자, 들, 의, 92, %, 가, 아, 학사, 학위, 를, ,, 47, %, 늘, ㄴ, 석사, 학위, 이상, 을, 갖, 고, 있음, 을, 밝혀내, 었, 다, ., 창업자, 들, 의, 세부, 전공, 을, 보, 면, 37, %, 만, 공학, ·, 컴퓨터, 기술, 이, 며, ,, 수학, 전공자, 는, 2, %, 뿐, 이, 었, 다, ., 이, 들, 의, 전공, 은, 경영, ·, 회계, ·, 보건, ·, 예술, ·, 인문학, 등, 매우, 다양, 하, 었, 다, ., 컴퓨터, 주변, 기기, 제조, 업체, 로지텍, 의, 브랙, 크, ㄴ, 대, 럴, CEO, 도, 영문학, 을, 전공, 하, 었, 다, ., 최근, 내가, 그, 에게, \", 어떻, 게, 5, 년, 여, 만, 에, 회사, 주가, 를, 450, %, 올리, ㄹ, 수, 있, 었, 느냐, \", 고, 묻, 었, 더니, 그, 는, \", 우리, 회사, 가, 만들, 는, 모든, 제품, 의, 디자인, 을, 쉼, 없이, 고민, 하, 었, 기, 때문, 에, 가능, 하, 었, 다, ., 기술, 관련, 제품, 의, 성공, 에, 가장, 중요, 하, ㄴ, 것, 은, 디자인, \", 이, 라고, 답하, 었, 다, ., 4, 차, 산업, 혁명, 은, ', 혁신, 의, 규칙, ', 을, 바꾸, 는, 일, 이, 다, ., 여기, 에, 는, 컴퓨터, 와, 인공지능, ,, 디지털, 의술, ,, 로봇, 공학, ,, 합성, 생물학, 등, 광범위, 하, ㄴ, 기술, 이, 활용, 되, ㄴ다, ., 의학, ·, 인공지능, 과, 센서, 를, 융합, 하, 면, 인간, 의, 건강, 을, 진단, 하, 고, 질병, 을, 예방, 하, 는, ', 디지털, 의사, ', 를, 만들, ㄹ, 수, 있, 다, ., 유전체, 학과, 유전자, 편집, 을, 이용, 하, 어, 가뭄, 에, 강하, 고, 인류, 전체, 를, 먹이, 어, 살리, ㄹ, 새, 식물, 을, 개발, 하, ㄹ, 수, 있, 다, ., 인공지능, 로봇, 을, 사용하, 어, 노인, 들, 을, 위하, ㄴ, ', 디지털, 친구, ', 도, 가능, 하, 다, ., 초소형, 물질, 의, 발전, 은, 모든, 사람, 이, 충분히, 이용, 하, ㄹ, 수, 있, 는, ', 태양, 열, 저장, 기술, ', 의, 새, 시대, 를, 열, ㄹ, 것, 이, 다, ., 이런, 해결책, 을, 이끌어내, 는, 데는, 생물학, ·, 교육, ·, 의료, ·, 인간, 행동, 등, 여러, 분야, 에, 대하, ㄴ, 지식, 이, 필요, 하, 다, ., 우리, 가, 처하, ㄴ, 거대, 하, ㄴ, 사회, ·, 기술적, 도전, 에, 대처, 하, 려면, 인류, 를, 둘러싸, ㄴ, 다양, 하, ㄴ, 배경, 과, 맥락, 에, 대하, 어, 비판적, 사고, 능력, 이, 필수적, 이, 다, ., 일, 는, 인문학, 전공자, 들, 이, 가장, 잘, 훈련, 받, 은, 분야, 이, 다, ., 일례, 로, 음악, ·, 예술, ·, 문, 학과, 심리학, 에서, 비롯, 하, ㄴ, 공감, (, 共感, ), 능력, 은, 디자인, 에, 크, ㄴ, 장점, 이, 되, ㄴ다, ., 로마, 제국, 의, 흥망성쇠, 와, 계몽, 주의, 를, 공부, 하, ㄴ, 역사, 학도, 는, 기술, 의, 인간적, 요소, 와, 유용성, 에, 대하, ㄴ, 통찰력, 을, 가지, ㄹ, 수, 있, 다, ., 심리학, 전공자, 는, 사람, 에게, 동기, (, 動機, ), 부여, 가, 무엇, 이, 며, ,, 사용자, 들, 이, 원하, 는, 것, 이, 무엇, 이, ㄴ지, 를, 공학, 한, 분야, 에서, 만, 일하, 어, 오, ㄴ, 엔지니어, 들, 보다, 잘, 이해, 하, ㄹ, 수, 있, 다, ., 우리, 가, 상상, 하, 는, 물건, 을, 3, D, 로, 만들, ㄹ, 수, 있, 게, 되, 면, 음악가, 나, 아, 화가, 들, 의, 세상, 이, 되, ㄹ지, 도, 모르, ㄴ다, ., \", 자녀, 가, 미래, 에, 어떤, 직업, 을, 택하, 면, 좋, 겠, 는, 가, 아, \", 이, 라는, 질문, 을, 받, 을, 때, 나, 는, \", 아이, 들, 이, 스스로, 하, 고, 싶, 은, 것, 을, 선택, 하, 도록, 내버리, 어, 두, 는, 것, 이, 최선, \", 이, 라고, 답하, ㄴ다, ., 과거, 우리, 부모, 들, 이, 우리, 에게, 공부, 를, 강요, 하, 어서, 학습, 을, ', 억지로, 하, 어야, 하, 는, 따분, 하, ㄴ, 일, ', 로, 여기, 게, 하, 었, 더, ㄴ, 방식, 을, 따르, 아, 해선, 안, 되, ㄴ다, ., 그, 대신, 자녀, 가, 자신, 의, 열정, 을, 추구, 하, 고, 배우, 는, 것, 을, 즐기, ㄹ, 수, 있, 도록, 북돋, 아야, 하, ㄴ다, ., 기술, 을, 통하, 어, 놀랍, ㄴ, 미래, 를, 창조, 하, 고, 새롭, ㄴ, 산업, 혁명, 시대, 에, 리더, 가, 되, 기, 위하, 어, 한국, 에서, 는, 공학자, 들, 과, 손잡, 고, 일하, ㄹ, 음악가, 와, 화가, 가, 더, 많이, 필요, 하, 다, ., 이제, 는, 과학, ·, 공학, ·, 의학, 뿐, 아니, 라, 창, 의, 성과, 디자인, 에, 도, 진정하, ㄴ, 관심, 을, 쏟, 아야, 하, ㄴ다, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCa_KrF1TvV-",
        "colab_type": "code",
        "outputId": "5feac065-7f04-4b32-c8d0-92b49ee843e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "# 코모란(Komoran) 품사 태깅\n",
        "komoranTag = []\n",
        "for token in komoran_tokens:\n",
        "  komoranTag += komoran.pos(token)\n",
        "print(komoranTag[:10])\n",
        "\n",
        "# 한나눔(Hannanum) 품사 태깅\n",
        "hannanumTag = []\n",
        "for token in hannanum_tokens:\n",
        "  hannanumTag += hannanum.pos(token)\n",
        "print(hannanumTag[:10])\n",
        "\n",
        "\n",
        "# Okt 품사 태깅\n",
        "oktTag = []\n",
        "for token in okt_tokens:\n",
        "  oktTag += okt.pos(token)\n",
        "print(oktTag[:10])\n",
        "\n",
        "\n",
        "# Kkma 품사 태깅\n",
        "kkmaTag = []\n",
        "for token in kkma_tokens:\n",
        "  kkmaTag += kkma.pos(token)\n",
        "print(kkmaTag[:10])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('교육', 'NNG'), ('을', 'NNG'), ('삶', 'NNG'), ('의', 'NNG'), ('최', 'NNP'), ('우선', 'MAG'), ('순위', 'NNP'), ('로', 'NNG'), ('두', 'MM'), ('고', 'MM')]\n",
            "[('교육', 'N'), ('을', 'N'), ('삶', 'N'), ('의', 'N'), ('최우선', 'N'), ('순위', 'N'), ('로', 'N'), ('두', 'N'), ('고', 'M'), ('있', 'N')]\n",
            "[('교육', 'Noun'), ('을', 'Josa'), ('삶', 'Noun'), ('의', 'Noun'), ('최', 'Noun'), ('우선', 'Noun'), ('순위', 'Noun'), ('로', 'Noun'), ('두고', 'Verb'), ('있는', 'Adjective')]\n",
            "[('교육', 'NNG'), ('을', 'NNG'), ('삶', 'NNG'), ('의', 'NNG'), ('최', 'XPN'), ('우선', 'MAG'), ('순위', 'NNG'), ('로', 'NNG'), ('두', 'NNG'), ('고', 'NNG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_DXxNKYoMj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}